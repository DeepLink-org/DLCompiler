diff --git a/python/src/ir.cc b/python/src/ir.cc
index 9945c6188..8fd1d2520 100644
--- a/python/src/ir.cc
+++ b/python/src/ir.cc
@@ -258,7 +258,12 @@ void init_triton_ir(py::module &&m) {
       .def("param_types", [](FunctionType &self) {
         return std::vector<Type>(self.getInputs().begin(),
                                  self.getInputs().end());
-      });
+      })
+      .def("result_types", [](FunctionType &self) {
+        return std::vector<Type>(self.getResults().begin(),
+                                 self.getResults().end());
+      })
+      ;
 
   py::class_<Location>(m, "location", py::module_local())
       .def("__str__", [](Location &self) {
@@ -1559,6 +1564,73 @@ void init_triton_ir(py::module &&m) {
                      IntegerType::get(operand.getContext(), 32)),
                  operand);
            })
+      .def("create_extract_slice",
+           [](TritonOpBuilder &self, Value &ful, std::vector<Value> &offs_vec,
+              std::vector<int> &sizs_vec, std::vector<int> &strd_vec) -> Value {
+             llvm::SmallVector<Value> offsets;
+             for (const auto &o : offs_vec) {
+               auto oTy = o.getType();
+               if (!oTy.isIndex()) {
+                 auto v = self.create<arith::IndexCastOp>(
+                     self.getBuilder().getIndexType(), o);
+                 offsets.push_back(v);
+               } else {
+                 offsets.push_back(o);
+               }
+             }
+             llvm::SmallVector<Value> sizes;
+             llvm::SmallVector<int64_t> retSizes;
+             for (const auto &s : sizs_vec) {
+               auto v = self.create<arith::ConstantIndexOp>(s);
+               sizes.push_back(v);
+               retSizes.push_back(s);
+             }
+             llvm::SmallVector<Value> strides;
+             for (const auto &s : strd_vec) {
+               auto v = self.create<arith::ConstantIndexOp>(s);
+               strides.push_back(v);
+             }
+             auto retTy = RankedTensorType::get(
+                 retSizes,
+                 cast<RankedTensorType>(ful.getType()).getElementType());
+             auto ret = self.create<tensor::ExtractSliceOp>(retTy, ful, offsets,
+                                                            sizes, strides);
+             return ret;
+           })
+      .def("create_insert_slice",
+           [](TritonOpBuilder &self, Value &ful, Value &sub,
+              std::vector<Value> &offs_vec, std::vector<int> &sizs_vec,
+              std::vector<int> &strd_vec) -> Value {
+             llvm::SmallVector<Value> offsets;
+             for (const auto &o : offs_vec) {
+               auto oTy = o.getType();
+               if (!oTy.isIndex()) {
+                 auto v = self.create<arith::IndexCastOp>(
+                     self.getBuilder().getIndexType(), o);
+                 offsets.push_back(v);
+               } else {
+                 offsets.push_back(o);
+               }
+             }
+             llvm::SmallVector<Value> sizes;
+             llvm::SmallVector<int64_t> retSizes;
+             for (const auto &s : sizs_vec) {
+               auto v = self.create<arith::ConstantIndexOp>(s);
+               sizes.push_back(v);
+               retSizes.push_back(s);
+             }
+             llvm::SmallVector<Value> strides;
+             for (const auto &s : strd_vec) {
+               auto v = self.create<arith::ConstantIndexOp>(s);
+               strides.push_back(v);
+             }
+             auto retTy = RankedTensorType::get(
+                 retSizes,
+                 cast<RankedTensorType>(ful.getType()).getElementType());
+             auto ret = self.create<tensor::InsertSliceOp>(sub, ful, offsets,
+                                                           sizes, strides);
+             return ret;
+           })
       // Force GPU barrier
       .def("create_barrier",
            [](TritonOpBuilder &self) { self.create<mlir::gpu::BarrierOp>(); })
diff --git a/python/triton/compiler/code_generator.py b/python/triton/compiler/code_generator.py
index d8ca58d8d..56db098b8 100644
--- a/python/triton/compiler/code_generator.py
+++ b/python/triton/compiler/code_generator.py
@@ -15,6 +15,10 @@ from ..runtime.jit import _normalize_ty, get_jit_fn_file_line
 from ..runtime import JITFunction
 from .errors import (CompilationError, CompileTimeAssertionFailure, UnsupportedLanguageConstruct)
 from types import ModuleType
+import logging
+
+logging = logging.getLogger(__name__)
+# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
 
 
 def mangle_ty(ty):
@@ -188,6 +192,61 @@ class ContainsReturnChecker(ast.NodeVisitor):
     def visit_Call(self, node: ast.Call) -> bool:
         return self.visit(node.func)
 
+def _get_triton_dtype(ir_type):
+    """将IR类型转换为Triton dtype"""
+    # 处理指针类型（通过类型名称判断）
+    if "ptr" in str(ir_type):
+        raise NotImplementedError("Pointer type conversion is not implemented yet.")
+    # 处理标量类型
+    type_str = str(ir_type)
+    logging.error(f"type_str: {type_str}")
+    if type_str == "i1":
+        return language.int1
+    elif type_str.startswith("i"):
+        return getattr(language, f"int{type_str[1:]}")
+    elif type_str.startswith("f"):
+        return getattr(language, f"float{type_str[1:]}")
+    return language.void
+
+class InlineLambda:
+    def __init__(self, node, closure_values, closure_names, arg_names):
+        self.node = node          # AST节点
+        self.closure_values = closure_values
+        self.closure_names = closure_names
+        self.arg_names = arg_names
+    
+    def __call__(self, *args, generator=None):
+        if generator is None:
+            raise RuntimeError("Generator must be provided for Lambda inlining")
+        
+        # 保存当前状态
+        old_lscope = generator.lscope.copy()
+        old_local_defs = generator.local_defs.copy()
+        old_insert_block = generator.builder.get_insertion_block()
+        
+        try:
+            # 创建闭包变量映射
+            closure_map = {}
+            for name, value in zip(self.closure_names, self.closure_values):
+                closure_map[name] = value
+            
+            # 创建参数映射
+            param_map = {}
+            for name, value in zip(self.arg_names, args):
+                param_map[name] = value
+            
+            # 合并作用域
+            generator.lscope = {**old_lscope, **closure_map, **param_map}
+            generator.local_defs = {**old_local_defs, **closure_map, **param_map}
+            
+            # 内联lambda体
+            return generator.visit(self.node.body)
+        finally:
+            # 恢复状态
+            generator.lscope = old_lscope
+            generator.local_defs = old_local_defs
+            if old_insert_block:
+                generator.builder.set_insertion_point_to_end(old_insert_block)
 
 class CodeGenerator(ast.NodeVisitor):
 
@@ -349,6 +408,7 @@ class CodeGenerator(ast.NodeVisitor):
                 break
 
     def visit_Module(self, node):
+        # logging.error(f"Visiting Module node: {ast.dump(node, indent=4)}")
         ast.NodeVisitor.generic_visit(self, node)
 
     def visit_List(self, node):
@@ -383,7 +443,42 @@ class CodeGenerator(ast.NodeVisitor):
         post_ret_block = self.builder.create_block()
         self.builder.set_insertion_point_to_end(post_ret_block)
 
+
+    def visit_Lambda(self, node):
+        # 1. 提取参数名
+        arg_names = [arg.arg for arg in node.args.args]
+        
+        # 2. 识别闭包变量
+        class ClosureCollector(ast.NodeVisitor):
+            def __init__(self):
+                self.vars = set()
+            
+            def visit_Name(self, node):
+                if isinstance(node.ctx, ast.Load):
+                    self.vars.add(node.id)
+                self.generic_visit(node)
+        
+        collector = ClosureCollector()
+        collector.visit(node.body)
+        
+        # 从当前作用域中筛选闭包变量
+        closure_vars = {}
+        closure_names = []
+        for var_name in collector.vars:
+            if var_name in self.lscope and var_name not in arg_names:
+                closure_vars[var_name] = self.lscope[var_name]
+                closure_names.append(var_name)
+        
+        # 3. 返回可内联的lambda对象
+        return InlineLambda(
+            node=node,
+            closure_values=list(closure_vars.values()),
+            closure_names=closure_names,
+            arg_names=arg_names
+        )
+
     def visit_FunctionDef(self, node):
+        # logging.error(f"Visiting FunctionDef node: {ast.dump(node, indent=4)}")
         arg_names, kwarg_names = self.visit(node.args)
         if self.fn:
             raise self._unsupported(node, "nested function definition is not supported.")
@@ -486,6 +581,7 @@ class CodeGenerator(ast.NodeVisitor):
         return self.visit_Assign(node)
 
     def visit_Assign(self, node):
+        # logging.error(f"Visiting Assign node: {ast.dump(node, indent=4)}")
         _names = []
         if isinstance(node, ast.AnnAssign):
             _names += [self.visit(node.target)]
@@ -681,6 +777,7 @@ class CodeGenerator(ast.NodeVisitor):
             self.set_value(name, new_tensor)
 
     def visit_If(self, node):
+        # logging.error(f"Visiting If node: {ast.dump(node, indent=4)}")
         cond = self.visit(node.test)
 
         if _is_triton_tensor(cond):
@@ -910,7 +1007,8 @@ class CodeGenerator(ast.NodeVisitor):
             return
         num_stages = None
         loop_unroll_factor = None
-        if IteratorClass is language.range:
+        bind_sub_block = None
+        if IteratorClass in [language.range, language.extra.deeplink.parallel]:
             iterator = IteratorClass(*iter_args, **iter_kwargs)
             # visit iterator arguments
             # note: only `range` iterator is supported now
@@ -920,6 +1018,8 @@ class CodeGenerator(ast.NodeVisitor):
             step = iterator.step
             num_stages = iterator.num_stages
             loop_unroll_factor = iterator.loop_unroll_factor
+            if (IteratorClass is language.extra.deeplink.parallel):
+                bind_sub_block = iterator.bind_sub_block
         elif IteratorClass is range:
             # visit iterator arguments
             # note: only `range` iterator is supported now
@@ -992,6 +1092,8 @@ class CodeGenerator(ast.NodeVisitor):
                 for_op.set_attr("tt.num_stages", self.builder.get_int32_attr(num_stages))
             if loop_unroll_factor is not None:
                 for_op.set_attr("tt.loop_unroll_factor", self.builder.get_int32_attr(loop_unroll_factor))
+            if (bind_sub_block is not None) and bind_sub_block:
+                for_op.set_attr("bind_sub_block", self.builder.get_bool_attr(bind_sub_block))
 
             self.scf_stack.append(node)
             self.builder.set_insertion_point_to_start(for_op.get_body(0))
@@ -1095,7 +1197,16 @@ class CodeGenerator(ast.NodeVisitor):
             return tuple(results)
 
     def visit_Call(self, node):
+        # logging.error(f"Visiting Call node: {ast.dump(node, indent=4)}")
         fn = _unwrap_if_constexpr(self.visit(node.func))
+        
+        if isinstance(fn, InlineLambda):
+            # 获取参数
+            args = [self.visit(arg) for arg in node.args]
+            
+            # 内联执行lambda体
+            return fn(*args, generator=self)
+
         static_implementation = self.statically_implemented_functions.get(fn)
         if static_implementation is not None:
             return static_implementation(self, node)
diff --git a/python/triton/language/semantic.py b/python/triton/language/semantic.py
index 8e9f87b5e..b6bdfe2e6 100644
--- a/python/triton/language/semantic.py
+++ b/python/triton/language/semantic.py
@@ -109,6 +109,9 @@ def computation_type_impl(a_ty: tl.dtype, a_is_scalar: bool, b_ty: tl.dtype, b_i
 
 
 def to_tensor(x, builder, check_type: bool = True):
+    # from ..compiler.code_generator import LambdaFunction
+    from ..compiler.code_generator import InlineLambda
+
     if isinstance(x, bool):
         return tl.tensor(builder.get_int1(x), tl.int1)
     # Note: compile-time const integers are represented by unsigned values
@@ -138,10 +141,21 @@ def to_tensor(x, builder, check_type: bool = True):
         return full((), x, dtype=dtype, builder=builder)
 
     elif isinstance(x, tl.constexpr):
+        print(f"zmz debug to_tensor, type is tl.constexpr: {x}", flush=True)
         return to_tensor(x.value, builder)
+    # elif isinstance(x, LambdaFunction):
+    #     print(f"zmz debug to_tensor, type is LambdaFunction: {x}", flush=True)
+    #     rtn = x(builder=builder)
+    #     print(f"zmz debug to_tensor, rtn is {rtn}", flush=True)
+    #     return rtn
+    elif isinstance(x, InlineLambda):
+        return x
     elif isinstance(x, tl.tensor):
         return x
     if check_type:
+        print(f"zmz debug to_tensor: {x} {type(x)}")
+        import pdb
+        pdb.set_trace()
         raise TypeError(f"cannot convert {x} of type {type(x)} to tensor")
     return x
 
