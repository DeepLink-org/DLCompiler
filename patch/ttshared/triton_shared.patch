diff --git a/include/triton-shared/Dialect/TritonStructured/IR/TritonStructuredDialect.td b/include/triton-shared/Dialect/TritonStructured/IR/TritonStructuredDialect.td
index 17c3ce9..30b88eb 100644
--- a/include/triton-shared/Dialect/TritonStructured/IR/TritonStructuredDialect.td
+++ b/include/triton-shared/Dialect/TritonStructured/IR/TritonStructuredDialect.td
@@ -233,8 +233,8 @@ def TTS_GetStructuredStateOp : TTS_Op<"get_structured_state", [AttrSizedResultSe
   let summary = "Placeholder for the structured pointer states computed during PtrAnalysis.";
   let description = "Used to pass the offsets and strides to scf.for op to simplify IR rewrites.";
 
-  let arguments = (ins AnyTypeOf<[TT_PtrLike, I32Tensor]>:$input);
-  let results = (outs AnyTypeOf<[TT_PtrLike, I32Tensor]>:$structured, Variadic<Index>:$offsets, Variadic<Index>:$strides);
+  let arguments = (ins AnyTypeOf<[TT_PtrLike, TT_IndexTensorLike]>:$input);
+  let results = (outs AnyTypeOf<[TT_PtrLike, TT_IndexTensorLike]>:$structured, Variadic<Index>:$offsets, Variadic<Index>:$strides);
 
   let builders = [
     OpBuilder<(ins "Value":$input)>,
diff --git a/lib/Analysis/UseAnalysis.cpp b/lib/Analysis/UseAnalysis.cpp
index 62e4508..2d81db4 100644
--- a/lib/Analysis/UseAnalysis.cpp
+++ b/lib/Analysis/UseAnalysis.cpp
@@ -120,12 +120,19 @@ LogicalResult triton::runUseAnalysis(triton::FuncOp &funcOp) {
       LLVM_DEBUG({ op->setAttr("Undefined", UnitAttr::get(context)); });
       return;
     } else if (useType == UseType::MetaUse) {
-      assert(op->getNumResults() == 1 &&
-             "Ops used for meta computation are expected to have one result");
-      // Only set the tag if the operation uses tensors
-      if (isa<ShapedType>(op->getResult(0).getType())) {
-        // Setting tag for erasing op later
-        op->setAttr("MetaUse", UnitAttr::get(context));
+      auto opName = op->getName().getStringRef();
+      // if (!isa<mlir::scf::WhileOp>(op)) {
+      //   assert(op->getNumResults() == 1 &&
+      //         "Ops used for meta computation are expected to have one result");
+      // }
+      for (auto it = 0; it < op->getNumResults(); ++it) {
+        // Only set the tag if the operation uses tensors
+        if (isa<ShapedType>(op->getResult(it).getType()) ||
+            (isa<triton::BitcastOp>(op) &&
+             isa<PointerType>(op->getResult(it).getType()))) {
+          // Setting tag for erasing op later
+          op->setAttr("MetaUse", UnitAttr::get(context));
+        }
       }
       return;
     } else if (useType == UseType::DataUse) {
diff --git a/lib/Conversion/TritonArithToLinalg/CMakeLists.txt b/lib/Conversion/TritonArithToLinalg/CMakeLists.txt
index 432dee7..f357483 100644
--- a/lib/Conversion/TritonArithToLinalg/CMakeLists.txt
+++ b/lib/Conversion/TritonArithToLinalg/CMakeLists.txt
@@ -1,6 +1,7 @@
 add_triton_library(TritonArithToLinalg
   TritonArithToLinalg.cpp
   TritonArithToLinalgPass.cpp
+  ${TRTION_SHARED_NPU_SPECIFIC_SOURCES}/TritonArithToLinalg/NPUSpecific.cpp
 
   DEPENDS
   TritonArithToLinalgConversionPassIncGen
@@ -20,4 +21,6 @@ add_triton_library(TritonArithToLinalg
   TritonTilingExtIR
   TritonStructuredIR
   TritonSharedUtils
+
+  DICPUtils
 )
diff --git a/lib/Conversion/TritonArithToLinalg/TritonArithToLinalgPass.cpp b/lib/Conversion/TritonArithToLinalg/TritonArithToLinalgPass.cpp
index 8c86fe2..7a05c59 100644
--- a/lib/Conversion/TritonArithToLinalg/TritonArithToLinalgPass.cpp
+++ b/lib/Conversion/TritonArithToLinalg/TritonArithToLinalgPass.cpp
@@ -4,6 +4,8 @@
 // Licensed under the MIT license.
 //
 //===----------------------------------------------------------------------===//
+#include "dicp/Conversion/TritonToLinalgNPU/TritonArithToLinalg/NPUSpecific.h"
+#include "dicp/Utils/Utils.h"
 
 #include "mlir/Dialect/ControlFlow/IR/ControlFlow.h"
 #include "mlir/IR/BuiltinTypeInterfaces.h"
@@ -26,7 +28,7 @@
 
 using namespace mlir;
 using namespace triton;
-
+using namespace mlir::dicp;
 namespace mlir {
 namespace triton {
 #define GEN_PASS_DEF_TRITONARITHTOLINALG
@@ -124,7 +126,10 @@ public:
     target.addLegalOp<triton::FuncOp, triton::ReturnOp>();
 
     target.addDynamicallyLegalDialect<arith::ArithDialect, math::MathDialect>(
-        [](Operation *op) {
+        [&](Operation *op) {
+          if (isAscendBackend(moduleOp))
+            return linked::isLegalConstantAndTensorArithmeticOpForNPU(op);
+
           // Lower dense constant to linalg.fill
           if (auto constOp = dyn_cast<arith::ConstantOp>(op)) {
             if (!isa<RankedTensorType>(constOp.getResult().getType())) {
@@ -185,9 +190,14 @@ public:
       target.addLegalOp<triton::AssertOp>();
     }
 
-    triton::populateTritonArithToLinalgConversionPatterns(
-        pidsToFuncArgs, addptrToLinalg, assertToCf, transposeReduceToRank0,
-        patterns);
+    DISPATCH_BACKEND_CONVERSION_PATTERNS(
+      mlir::dicp::getBackend(moduleOp),
+      linked::populateTritonArithToLinalgNPUConversionPatterns(
+                          pidsToFuncArgs, addptrToLinalg, assertToCf,
+                          transposeReduceToRank0, patterns),
+      triton::populateTritonArithToLinalgConversionPatterns(
+                    pidsToFuncArgs, addptrToLinalg, assertToCf,
+                    transposeReduceToRank0, patterns));
 
     if (pidsToFuncArgs) {
       for (auto func : getOperation().getOps<triton::FuncOp>()) {
