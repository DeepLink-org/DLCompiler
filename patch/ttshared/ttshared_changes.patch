diff --git a/include/triton-shared/Conversion/TritonArithToLinalg/ConversionPatterns.hpp b/include/triton-shared/Conversion/TritonArithToLinalg/ConversionPatterns.hpp
index 7baee48..92c6559 100644
--- a/include/triton-shared/Conversion/TritonArithToLinalg/ConversionPatterns.hpp
+++ b/include/triton-shared/Conversion/TritonArithToLinalg/ConversionPatterns.hpp
@@ -157,6 +157,23 @@ static std::optional<unsigned> getBitWidth(Type a) {
 
 namespace {
 
+enum class InputPrecision : uint32_t {
+  TF32 = 0,
+  TF32x3 = 1,
+  IEEE = 2,
+  HF32 = 3,
+};
+::llvm::StringRef stringifyInputPrecision(InputPrecision val) {
+  switch (val) {
+    case InputPrecision::TF32: return "tf32";
+    case InputPrecision::TF32x3: return "tf32x3";
+    case InputPrecision::IEEE: return "ieee";
+    case InputPrecision::HF32: return "hf32";
+  }
+  return "";
+}
+
+
 //-----------------------------
 // Begin of monolithic only
 //-----------------------------
@@ -688,44 +705,71 @@ private:
   }
 
 public:
+  // Dimensions of collapesd tensor is all unbroadcast dims
+  SmallVector<int64_t> getUnbroadcastDims(RankedTensorType src,
+                                          RankedTensorType dst) const {
+    SmallVector<int64_t> unbroadcastDims;
+    auto srcShape = src.getShape();
+    auto dstShape = dst.getShape();
+
+    for (size_t i = 0; i < srcShape.size(); ++i) {
+      if (dstShape[i] == srcShape[i]) {
+        unbroadcastDims.emplace_back(srcShape[i]);
+      }
+    }
+    return unbroadcastDims;
+  }
+  // Here convert tt.broadcast to linalg.broadcast
+  //
+  // before
+  // %out = tt.broadcast %in : tensor<1x4x8xf32> -> tensor<128x4x8xf32>
+  //
+  // after
+  // %collpased = tensor.collapse_shape %in [[0, 1], [2]] :
+  //                                    tensor<1x4x8xf32> into tensor<4x8xf32>
+  // %out = linalg.broadcast ins(%collpased : tensor<4x8xf32>)
+  //                         outs(%empty : tensor<128x4x8xf32>) dimensions = [0]
   LogicalResult
   matchAndRewrite(triton::BroadcastOp op, OpAdaptor adaptor,
                   ConversionPatternRewriter &rewriter) const override {
-    auto loc = op.getLoc();
+    assert(op->getNumResults() == 1 && "BroadcastOp assumes single result");
 
-    assert(op->getNumResults() == 1 && "code assumes single result!");
     RankedTensorType sourceType =
         cast<RankedTensorType>(adaptor.getSrc().getType());
     RankedTensorType resultType = cast<RankedTensorType>(op.getType());
     auto elementType = resultType.getElementType();
     size_t resultRank = resultType.getRank();
+    auto loc = op.getLoc();
 
-    SmallVector<AffineMap> indexingMaps;
-    indexingMaps.reserve(op->getNumOperands() + op->getNumResults());
+    auto initEmpty =
+        rewriter.create<tensor::EmptyOp>(loc, resultType.getShape(), elementType);
 
-    indexingMaps.push_back(getBroadcastAffineMap(
-        op->getContext(), sourceType.getShape(), resultType.getShape()));
-    indexingMaps.append(op->getNumResults(),
-                        rewriter.getMultiDimIdentityMap(resultRank));
+    SmallVector<int64_t> broadcastDims =
+        getBroadcastDims(sourceType, resultType);
+    SmallVector<int64_t> unbroadcastDims =
+        getUnbroadcastDims(sourceType, resultType);
+
+    SmallVector<ReassociationIndices> collapseReassociationIndices;
+    auto collapseReassociationIndicesOptional =
+        getReassociationIndicesForCollapse(sourceType.getShape(),
+                                          unbroadcastDims);
+    if (!collapseReassociationIndicesOptional.has_value()) {
+      return rewriter.notifyMatchFailure(
+          op, "Failure with getReassociationIndicesForCollapse call");
+    }
+    collapseReassociationIndices = collapseReassociationIndicesOptional.value();
 
-    assert(op->getNumResults() == 1 && "code assumes single result!");
-    auto init = rewriter.create<tensor::EmptyOp>(loc, resultType.getShape(),
-                                                 elementType);
+    RankedTensorType collapseResultType =
+        RankedTensorType::get(unbroadcastDims, sourceType.getElementType());
 
-    auto linalgOp = rewriter.create<linalg::GenericOp>(
-        loc, op->getResultTypes(), ValueRange{adaptor.getSrc()},
-        ValueRange{init}, indexingMaps, getNParallelLoopsAttrs(resultRank),
-        [&](OpBuilder &nestedBuilder, Location nestedLoc,
-            ValueRange blockArgs) {
-          Value opResult = blockArgs[0];
-          nestedBuilder.create<linalg::YieldOp>(loc, opResult);
-        });
+    auto collpasedOp = rewriter.create<tensor::CollapseShapeOp>(
+        loc, collapseResultType, adaptor.getSrc(), collapseReassociationIndices);
 
-    linalgOp->setAttr("broadcastDims",
-                      rewriter.getDenseI64ArrayAttr(
-                          getBroadcastDims(sourceType, resultType)));
+    auto broadcastOp = rewriter.create<linalg::BroadcastOp>(
+        loc, collpasedOp, initEmpty,
+        rewriter.getDenseI64ArrayAttr(broadcastDims));
 
-    rewriter.replaceOp(op, linalgOp->getResults());
+    rewriter.replaceOp(op, broadcastOp.getResults());
     return success();
   }
 };
@@ -1132,42 +1176,27 @@ struct MatmulConverter : public OpConversionPattern<triton::DotOp> {
   LogicalResult
   matchAndRewrite(triton::DotOp op, OpAdaptor adaptor,
                   ConversionPatternRewriter &rewriter) const override {
-    auto loc = op.getLoc();
-    auto opa = op.getA();
-    auto opb = op.getB();
-    auto opc = op.getC();
-
+    auto opa = adaptor.getA();
+    auto opb = adaptor.getB();
+    auto opc = adaptor.getC();
     auto dstType = cast<RankedTensorType>(op.getType());
-    auto elementType = dstType.getElementType();
-    bool integers = elementType.isInteger();
-    bool skipC = isZeroTensor(opc, integers);
-    auto init =
-        rewriter.create<tensor::EmptyOp>(loc, dstType.getShape(), elementType);
-    TypedAttr constantAttr = integers ?
-      static_cast<TypedAttr>(rewriter.getIntegerAttr(elementType, 0)) :
-      static_cast<TypedAttr>(rewriter.getFloatAttr(elementType, 0));
-
-    auto zero = rewriter.create<mlir::arith::ConstantOp>(
-        op.getLoc(), elementType, constantAttr);
-
-    auto zeroes =
-        rewriter.create<linalg::FillOp>(loc, ValueRange{zero}, ValueRange{init})
-            .result();
-
-    auto res = rewriter
-                   .create<linalg::MatmulOp>(loc, ValueRange{opa, opb},
-                                             ValueRange{zeroes})
-                   .getResult(0);
-
-    if (!skipC) {
-      if (integers) {
-        res = rewriter.create<arith::AddIOp>(loc, opc, res);
-      } else {
-        res = rewriter.create<arith::AddFOp>(loc, opc, res);
-      }
+    auto inputPrec = op.getInputPrecision();
+
+    if (dstType.getRank() == 2) {
+      auto matmulOp = rewriter.replaceOpWithNewOp<linalg::MatmulOp>(
+          op, ValueRange{opa, opb}, ValueRange{opc});
+      matmulOp->setAttr(
+          "input_precison",
+          rewriter.getStringAttr(stringifyInputPrecision(inputPrec)));
+    } else if (dstType.getRank() == 3) {
+      auto matmulOp = rewriter.replaceOpWithNewOp<linalg::BatchMatmulOp>(
+          op, ValueRange{opa, opb}, ValueRange{opc});
+      matmulOp->setAttr(
+          "input_precison",
+          rewriter.getStringAttr(stringifyInputPrecision(inputPrec)));
+    } else {
+      llvm_unreachable("Datatype of DotOp operands could only be 2D or 3D");
     }
-
-    rewriter.replaceOp(op, res);
     return success();
   }
 };
diff --git a/lib/Analysis/UseAnalysis.cpp b/lib/Analysis/UseAnalysis.cpp
index 62e4508..d9aaec2 100644
--- a/lib/Analysis/UseAnalysis.cpp
+++ b/lib/Analysis/UseAnalysis.cpp
@@ -88,6 +88,20 @@ triton::UseAnalysis::visitOperation(Operation *op, ArrayRef<UseInfo *> operands,
   return success();
 }
 
+std::string stringifyUseType(UseType useTy) {
+  std::string ret;
+  if (useTy == UseType::MetaUse) {
+    ret = "MetaUse";
+  } else if (useTy == UseType::DataUse) {
+    ret = "DataUse";
+  } else if (useTy == UseType::MixUse) {
+    ret = "MixUse";
+  } else if (useTy == UseType::Undefined) {
+    ret = "Undefined";
+  }
+  return ret;
+}
+
 LogicalResult triton::runUseAnalysis(triton::FuncOp &funcOp) {
   MLIRContext *context = funcOp.getContext();
   SymbolTableCollection symbolTable;
@@ -101,6 +115,7 @@ LogicalResult triton::runUseAnalysis(triton::FuncOp &funcOp) {
 
   // Walk the func op, convert tags on operands to tags on operations
   funcOp.walk([&](Operation *op) {
+    llvm::errs() << "test op is " << *op << "\n";
     UseType useType = UseType::Undefined;
     for (auto result : op->getResults()) {
       auto use = solver.lookupState<UseInfo>(result);
@@ -115,18 +130,35 @@ LogicalResult triton::runUseAnalysis(triton::FuncOp &funcOp) {
         break;
       }
     }
+    llvm::errs() << "useType is " << stringifyUseType(useType) << ", op->getNumResults()=" << op->getNumResults() << "\n";
 
     if (useType == UseType::Undefined) {
       LLVM_DEBUG({ op->setAttr("Undefined", UnitAttr::get(context)); });
       return;
     } else if (useType == UseType::MetaUse) {
-      assert(op->getNumResults() == 1 &&
-             "Ops used for meta computation are expected to have one result");
-      // Only set the tag if the operation uses tensors
-      if (isa<ShapedType>(op->getResult(0).getType())) {
-        // Setting tag for erasing op later
-        op->setAttr("MetaUse", UnitAttr::get(context));
+      auto opName = op->getName().getStringRef();
+      // LLVM_DEBUG({
+        llvm::errs() << "Checking op: " << opName << "\n";
+        llvm::errs() << "Number of results: " << op->getNumResults() << "\n";
+        for (unsigned i = 0; i < op->getNumResults(); ++i) {
+          llvm::errs() << "Result " << i << " type: "
+                       << op->getResult(i).getType() << "\n";
+        }
+      // });
+      if (!isa<mlir::scf::WhileOp>(op)) {
+        assert(op->getNumResults() == 1 &&
+              "Ops used for meta computation are expected to have one result");
+      }
+      for (auto it = 0; it < op->getNumResults(); ++it) {
+        // Only set the tag if the operation uses tensors
+        if (isa<ShapedType>(op->getResult(it).getType()) ||
+            (isa<triton::BitcastOp>(op) &&
+             isa<PointerType>(op->getResult(it).getType()))) {
+          // Setting tag for erasing op later
+          op->setAttr("MetaUse", UnitAttr::get(context));
+        }
       }
+      llvm::errs() << "MetaUse op: " << opName << ", op is " << *op << "\n";
       return;
     } else if (useType == UseType::DataUse) {
       LLVM_DEBUG({ op->setAttr("DataUse", UnitAttr::get(context)); });
diff --git a/lib/Conversion/TritonToLinalg/TritonToLinalg.cpp b/lib/Conversion/TritonToLinalg/TritonToLinalg.cpp
index d85cab7..8cc0d24 100644
--- a/lib/Conversion/TritonToLinalg/TritonToLinalg.cpp
+++ b/lib/Conversion/TritonToLinalg/TritonToLinalg.cpp
@@ -90,5 +90,5 @@ void mlir::triton::populateTritonToLinalgConversionPatterns(
   // will be tried last. Incorrect ordering or having MetaOpConverter has lower
   // PatternBenefit will result in element-wise meta ops being converted to
   // linalg.generic ops.
-  linalg::populateElementwiseToLinalgConversionPatterns(patterns);
+//   linalg::populateElementwiseToLinalgConversionPatterns(patterns);
 }
diff --git a/lib/Conversion/TritonToLinalg/TritonToLinalgPass.cpp b/lib/Conversion/TritonToLinalg/TritonToLinalgPass.cpp
index 667c0b5..89ce192 100644
--- a/lib/Conversion/TritonToLinalg/TritonToLinalgPass.cpp
+++ b/lib/Conversion/TritonToLinalg/TritonToLinalgPass.cpp
@@ -172,7 +172,7 @@ public:
                 return isa<RankedTensorType>(type);
               });
 
-          return !operateOnTensors;
+          return true || !operateOnTensors;
         });
 
     triton::populateTritonToLinalgConversionPatterns(
